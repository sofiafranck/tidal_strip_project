{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating path so jupyter notebook knows where to look for the crusher module that i downloaded\n",
    "import sys\n",
    "sys.path.append('/Users/sofia/Research/Work/Project 1/Modules/crusher-master')\n",
    "\n",
    "# basic imports\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import multiprocessing as mp\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "# import my code crusher\n",
    "import crusher\n",
    "from crusher.galaxy import GalaxyMap\n",
    "from crusher.data import BeneMassAgeZMaps\n",
    "from crusher import visual\n",
    "from crusher import combine\n",
    "from crusher import profile\n",
    "\n",
    "# import benedikt code, colossus\n",
    "from colossus.halo import mass_so\n",
    "from colossus.cosmology import cosmology\n",
    "\n",
    "# I get a latex error, so this fixes it\n",
    "#matplotlib.rcParams['text.usetex']=False\n",
    "#matplotlib.rcParams['text.latex.unicode']=False\n",
    "\n",
    "# make axis label sizes bigger\n",
    "plt.rcParams['xtick.labelsize']=24\n",
    "plt.rcParams['ytick.labelsize']=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of files\n",
    "file_list_lr_100 = ['galaxies_progmaps_lr_tng100_099.hdf5',\n",
    "                    'galaxies_progmaps_lr_tng100_084.hdf5', \n",
    "                    'galaxies_progmaps_lr_tng100_072.hdf5',\n",
    "                    'galaxies_progmaps_lr_tng100_067.hdf5', \n",
    "                    'galaxies_progmaps_lr_tng100_059.hdf5',\n",
    "                    'galaxies_progmaps_lr_tng100_050.hdf5',\n",
    "                    'galaxies_progmaps_lr_tng100_040.hdf5',\n",
    "                    'galaxies_progmaps_lr_tng100_033.hdf5']\n",
    "\n",
    "file_list_lr_300 = ['galaxies_progmaps_lr_tng300_099.hdf5',\n",
    "                    'galaxies_progmaps_lr_tng300_084.hdf5', \n",
    "                    'galaxies_progmaps_lr_tng300_072.hdf5',\n",
    "                    'galaxies_progmaps_lr_tng300_067.hdf5', \n",
    "                    'galaxies_progmaps_lr_tng300_059.hdf5',\n",
    "                    'galaxies_progmaps_lr_tng300_050.hdf5',\n",
    "                    'galaxies_progmaps_lr_tng300_040.hdf5']\n",
    "\n",
    "file_list_hr_300 = ['galaxies_progmaps_hr_tng300_099.hdf5',\n",
    "                    'galaxies_progmaps_hr_tng300_084.hdf5', \n",
    "                    'galaxies_progmaps_hr_tng300_072.hdf5',\n",
    "                    'galaxies_progmaps_hr_tng300_067.hdf5', \n",
    "                    'galaxies_progmaps_hr_tng300_059.hdf5',\n",
    "                    'galaxies_progmaps_hr_tng300_050.hdf5',\n",
    "                    'galaxies_progmaps_hr_tng300_040.hdf5']\n",
    "\n",
    "file_path_100 = '/users/sofiafranck/Data/TNG100/'\n",
    "file_path_300 = '/users/sofiafranck/Data/TNG300/'\n",
    "\n",
    "file_list = file_list_lr_300\n",
    "file_path = file_path_300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "form to look at a certain galaxy at a certain snapshot: np.array(tng_data_z['tree_*'])[galaxy_index, snapnum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and random data that I might as well grab now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/users/sofiafranck/Data/TNG300/galaxies_progmaps_lr_tng300_099.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m205\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;66;03m#kpc\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# some data sets at z=0 and some of their fields\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m tng_data_099 \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m tng_bene_099 \u001b[38;5;241m=\u001b[39m BeneMassAgeZMaps(file_path \u001b[38;5;241m+\u001b[39m file_list[\u001b[38;5;241m0\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtng300_hr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# basic info for z = 0 snapshot\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/h5py/_hl/files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    525\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    527\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    528\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    529\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    530\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    531\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    532\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 533\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/h5py/_hl/files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    225\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    228\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/users/sofiafranck/Data/TNG300/galaxies_progmaps_lr_tng300_099.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# value for h with h0 = 70 km s^-1 Mpc^-1\n",
    "h = 0.7\n",
    "box_size = 205 * 1000 #kpc\n",
    "\n",
    "# some data sets at z=0 and some of their fields\n",
    "tng_data_099 = h5py.File(file_path + file_list[0], 'r')\n",
    "tng_bene_099 = BeneMassAgeZMaps(file_path + file_list[0], label='tng300_hr')\n",
    "\n",
    "# basic info for z = 0 snapshot\n",
    "is_primary_099 = np.array(tng_data_099['catgrp_is_primary'])\n",
    "subhalo_mass_099 = np.array(tng_data_099['catsh_SubhaloMassType'])\n",
    "\n",
    "# grab needed trees\n",
    "tree_Group_M_TopHat200 = np.array(tng_data_099['tree_Group_M_TopHat200'])\n",
    "tree_SnapNum = np.array(tng_data_099['tree_SnapNum'])\n",
    "tree_SubhaloCM = np.array(tng_data_099['tree_SubhaloCM'])\n",
    "tree_SubhaloMassType = np.array(tng_data_099['tree_SubhaloMassType'])\n",
    "tree_SubhaloPos = np.array(tng_data_099['tree_SubhaloPos'])\n",
    "tree_SubhaloSFR = np.array(tng_data_099['tree_SubhaloSFR'])\n",
    "tree_SubhaloVel = np.array(tng_data_099['tree_SubhaloVel'])\n",
    "tree_SubhaloVelDisp = np.array(tng_data_099['tree_SubhaloVelDisp'])\n",
    "tree_SubhaloVmax = np.array(tng_data_099['tree_SubhaloVmax'])\n",
    "tree_is_primary = np.array(tng_data_099['tree_is_primary'])\n",
    "tree_subfind_id = np.array(tng_data_099['tree_subfind_id'])\n",
    "\n",
    "print(tree_SnapNum, tree_SubhaloMassType)\n",
    "\n",
    "# redshift and time lists\n",
    "redshifts = np.array(tng_data_099['info']['tree_z'])\n",
    "times = np.array(tng_data_099['info']['tree_t'])\n",
    "snaps = np.array(tng_data_099['info']['tree_snaps'])\n",
    "\n",
    "# redshifts and time lists at the snapshots\n",
    "snapshots = [99, 84, 72, 67, 59, 50, 40]\n",
    "snap_times = times[snapshots]\n",
    "snap_z = redshifts[snapshots]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some functions to grab data from tng data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create galaxy map from crusher and find m100\n",
    "def get_masses(tng_data, i, m10_add=True, m100_add=True, proj='xy'):\n",
    "    gal = GalaxyMap(tng_data, i ,proj=proj, aper_force=None)\n",
    "\n",
    "    # m10 and m100\n",
    "    r10, m10 = profile.aperture_masses(gal.info, gal.maps['mass_gal'], rad=100)\n",
    "    r100, m100 = profile.aperture_masses(gal.info, gal.maps['mass_gal'], rad=100)\n",
    "\n",
    "    # add to list what want to return\n",
    "    return_list = list()\n",
    "    if m10_add == True:\n",
    "        return_list.append(m10)\n",
    "        \n",
    "    if m100_add == True:\n",
    "        return_list.append(m100)\n",
    "        \n",
    "    return return_list\n",
    "\n",
    "# some functions to look at tng data across snapshots\n",
    "\n",
    "# function from joe to find ids of galaxies in different snapshot\n",
    "def find_id(hdf0, hdf1, snapnum):\n",
    "    ids = hdf0['tree_subfind_id'][:,snapnum]\n",
    "    idx = hdf1['catsh_id'][:].argsort()\n",
    "\n",
    "    match = hdf1['catsh_id'][:].searchsorted(ids, sorter=idx)\n",
    "    goodmatch = hdf1['catsh_id'][:][idx][match]==ids\n",
    "\n",
    "    # print(np.isclose(hdf0['tree_SubhaloMassType'][:,snapnum,4][i], hdf1['scalar_star_mass'][:][idx][match][i]))\n",
    "    \n",
    "    return match, goodmatch, idx\n",
    "\n",
    "# function to find catgrp_id for any snapshot\n",
    "def find_catgrp_id(tng_data_z, match, idx, high_z):\n",
    "    # grab positions and convert\n",
    "    if high_z == False:\n",
    "        tng_grp_id = np.array(tng_data_z['catgrp_id'])\n",
    "        \n",
    "    if high_z == True:\n",
    "        tng_grp_id = np.array(tng_data_z['catgrp_id'])[idx]\n",
    "\n",
    "    return tng_grp_id\n",
    "\n",
    "# function to find 3d masses for any snapshot\n",
    "# kind of unfortunate to have separate data for insitu, exsitu, other subhalo (oshs) and fuzz,\n",
    "# so i need to grab them all separately. looking back, i suppose i couldve used a pandas dataframe,\n",
    "# but i don't think thats not a big issue \n",
    "def find_3d_masses(tng_data_z, match, idx, sat, high_z):\n",
    "    if high_z == False:\n",
    "        tng_volume = np.array(tng/q_data_z['profile_bins_volume'])\n",
    "        tng_bins = np.array(tng_data_z['profile_bins'])\n",
    "        \n",
    "        tng_bound = np.array(tng_data_z['profile_star_rho_3d'])\n",
    "        tng_bound_ins = np.array(tng_data_z['profile_star_rho_insitu_3d'])\n",
    "        tng_bound_exs = np.array(tng_data_z['profile_star_rho_exsitu_3d'])\n",
    "        \n",
    "        tng_oshs = np.array(tng_data_z['profile_star_rho_oshs_3d'])\n",
    "        tng_fuzz = np.array(tng_data_z['profile_star_rho_fuzz_3d'])\n",
    "\n",
    "        # make sat specific\n",
    "        volume = tng_volume[match][sat]\n",
    "        bins = tng_bins[match][sat]\n",
    "        \n",
    "        bound = tng_bound[match][sat]\n",
    "        bound_ins = tng_bound_ins[match][sat]\n",
    "        bound_exs = tng_bound_exs[match][sat]\n",
    "        \n",
    "        oshs = tng_oshs[match][sat]\n",
    "        fuzz = tng_fuzz[match][sat]\n",
    "\n",
    "    if high_z == True:\n",
    "        tng_volume = np.array(tng_data_z['profile_bins_volume'])[idx]\n",
    "        tng_bins = np.array(tng_data_z['profile_bins'])[idx]\n",
    "        \n",
    "        tng_bound = np.array(tng_data_z['profile_star_rho_3d'])[idx]\n",
    "        tng_bound_ins = np.array(tng_data_z['profile_star_rho_insitu_3d'])[idx]\n",
    "        tng_bound_exs = np.array(tng_data_z['profile_star_rho_exsitu_3d'])[idx]\n",
    "        \n",
    "        tng_oshs = np.array(tng_data_z['profile_star_rho_oshs_3d'])[idx]\n",
    "        tng_fuzz = np.array(tng_data_z['profile_star_rho_fuzz_3d'])[idx]\n",
    "\n",
    "        # make sat specific\n",
    "        volume = tng_volume[match[sat]]\n",
    "        bins = tng_bins[match[sat]]\n",
    "        \n",
    "        bound = tng_bound[match[sat]]\n",
    "        bound_ins = tng_bound_ins[match[sat]]\n",
    "        bound_exs = tng_bound_exs[match[sat]]\n",
    "        \n",
    "        oshs = tng_oshs[match[sat]]\n",
    "        fuzz = tng_fuzz[match[sat]]\n",
    "    \n",
    "    return bound, bound_ins, bound_exs, oshs, fuzz, volume, bins\n",
    "    \n",
    "# function to find primary across z\n",
    "def find_primary(match, idx, sat, high_z):\n",
    "    if high_z == False:\n",
    "        is_primary = np.array(tng_data_z['catgrp_is_primary'])\n",
    "\n",
    "        primary = is_primary[match][sat]\n",
    "\n",
    "    if high_z == True:\n",
    "        is_primary = np.array(tng_data_z['catgrp_is_primary'])[idx]\n",
    "\n",
    "        primary = is_primary[match[sat]]\n",
    "\n",
    "    if primary == 1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "# function to find star formation rate (should increase mass of satellite, or lessen visual effects of stripping)\n",
    "def find_star_formation(tng_data_z, match, idx, sat, high_z):\n",
    "    if high_z == False:\n",
    "        tng_sf = np.array(tng_data_z['catsh_SubhaloSFR'])\n",
    "\n",
    "        sat_sf = tng_sf[match][sat]\n",
    "\n",
    "    if high_z == True:\n",
    "        tng_sf = np.array(tng_data_z['catsh_SubhaloSFR'])[idx]\n",
    "\n",
    "        sat_sf = tng_sf[match[sat]]\n",
    "\n",
    "    return sat_sf\n",
    "\n",
    "# function to find distances between satellite and central\n",
    "def find_distances(tng_data, match, idx, sat, central, redshift, high_z):\n",
    "    # value for h with h0 = 70 km s^-1 Mpc^-1\n",
    "    h = 0.7\n",
    "\n",
    "    if high_z == False:\n",
    "        tng_cm = np.array(tng_data['catsh_SubhaloCM'])\n",
    "\n",
    "        sat_cm = tng_cm[match][sat]\n",
    "        central_cm = tng_cm[match][central]\n",
    "\n",
    "    if high_z == True:\n",
    "        tng_cm = np.array(tng_data['catsh_SubhaloCM'])[idx]\n",
    "\n",
    "        sat_cm = tng_cm[match[sat]]\n",
    "        central_cm = tng_cm[match[central]]\n",
    "\n",
    "    # now to find the distance between the satellite and the central\n",
    "    # convert from comoving coords to kpc\n",
    "    sat_cm_converted = sat_cm / ((1 + redshift) * h)\n",
    "    central_cm_converted = central_cm / ((1 + redshift) * h)\n",
    "\n",
    "    #find distance -- bc sat is bound to central, must be close in z axis. so just find projection distance instead of 3d distance\n",
    "    distance = math.sqrt(((sat_cm_converted[0] - central_cm_converted[0]) ** 2) + ((sat_cm_converted[1] - central_cm_converted[1]) ** 2))\n",
    "\n",
    "    return distance\n",
    "    \n",
    "# misc functions\n",
    "\n",
    "# function to find norm of array\n",
    "def find_norm_array(array): \n",
    "    norm_factor = np.nanmax(array) - np.nanmin(array)\n",
    "\n",
    "    array_norm = list()\n",
    "    for i in array:\n",
    "        i_norm = (i - np.nanmin(array)) / norm_factor\n",
    "\n",
    "        array_norm.append(i_norm)\n",
    "        \n",
    "    return array_norm\n",
    "\n",
    "# function to linearly interpolate the data\n",
    "def interpolate(profile, rad, start, end):\n",
    "    r = np.linspace(start, end, 700)\n",
    "    \n",
    "    interp = interp1d(rad,\n",
    "                      profile,\n",
    "                      bounds_error=False,\n",
    "                      kind='slinear')\n",
    "\n",
    "    # finish interpolating\n",
    "    interp_map = interp(r)\n",
    "\n",
    "    return interp_map\n",
    "\n",
    "# function to convert comoving coords to distance\n",
    "def convert_dist(sat_cm, central_cm):\n",
    "    # separate center of masses into x,y,z and subtract sat and cent. also do boundary conditions\n",
    "    dist_x = (sat_cm[:,0] - central_cm[:,0])\n",
    "    dist_y = (sat_cm[:,1] - central_cm[:,1])\n",
    "    dist_z = (sat_cm[:,2] - central_cm[:,2])\n",
    "\n",
    "    # apply edge cases (one end of the box is connected with the other)\n",
    "    # this took a little bit to figure out.\n",
    "    dist_x = np.array([(box_size - abs(i)) if abs(i) > (box_size / 2) else i for i in dist_x])\n",
    "    dist_y = np.array([(box_size - abs(i)) if abs(i) > (box_size / 2) else i for i in dist_y])\n",
    "    dist_z = np.array([(box_size - abs(i)) if abs(i) > (box_size / 2) else i for i in dist_z])\n",
    "    \n",
    "    # convert distances from comoving into physical\n",
    "    dist_x = np.array([(i  / ((1 + redshifts[list(dist_x).index(i)]) * h)) for i in dist_x])\n",
    "    dist_y = np.array([(i  / ((1 + redshifts[list(dist_y).index(i)]) * h)) for i in dist_y])\n",
    "    dist_z = np.array([(i  / ((1 + redshifts[list(dist_z).index(i)]) * h)) for i in dist_z])\n",
    "\n",
    "    # combine into a single distance number\n",
    "    distance = np.sqrt((dist_x ** 2) + (dist_y ** 2) + (dist_z ** 2))\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to get the distances, etc for a specific satellite (main data grabbing function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that im pulling variables from outside the function because its just quicker\n",
    "\n",
    "def find_data(sat, central, start_index, start, end_index, end):\n",
    "    box_size = 205 * 1000 #kpc\n",
    "    \n",
    "    # grab necessary info from trees\n",
    "    sat_sn = tree_SnapNum[sat, :]\n",
    "\n",
    "    sat_cm = tree_SubhaloCM[sat, :]\n",
    "    central_cm = tree_SubhaloCM[central, :]\n",
    "\n",
    "    sat_mass = tree_SubhaloMassType[sat, :]\n",
    "    stellar_mass = sat_mass[:,4]\n",
    "    \n",
    "    central_mvir = tree_Group_M_TopHat200[central, :]\n",
    "    \n",
    "    sat_sfr = tree_SubhaloSFR[sat, :]\n",
    "\n",
    "    sat_is_primary = tree_is_primary[sat, :]\n",
    "\n",
    "    # need to remove any points with -inf masses and the first instance of lists (not accurate)\n",
    "    indices_mass = np.where(stellar_mass == -np.inf)\n",
    "    indices_pos = np.append(np.where(sat_cm == [0,0,0]), np.where(central_cm == [0,0,0]))\n",
    "\n",
    "    indices = np.append(indices_mass, indices_pos)\n",
    "    full_indices = np.append(np.array([0,1]), indices)\n",
    "    \n",
    "    # remove these points with -inf masses from other lists as well\n",
    "    full_indices = list(dict.fromkeys(full_indices))\n",
    "    \n",
    "    sat_sn = np.delete(sat_sn, full_indices, axis=0)\n",
    "    sat_cm = np.delete(sat_cm, full_indices, axis=0)\n",
    "    central_cm = np.delete(central_cm, full_indices, axis=0)\n",
    "    sat_mass = np.delete(sat_mass, full_indices, axis=0)\n",
    "    central_mvir = np.delete(central_mvir, full_indices, axis=0)\n",
    "    sat_sfr = np.delete(sat_sfr, full_indices, axis=0)\n",
    "    sat_is_primary = np.delete(sat_is_primary, full_indices, axis=0)\n",
    "\n",
    "    times_o = np.delete(times, full_indices, axis=0)\n",
    "    \n",
    "    # just grabbing the stellar mass from the array of masses\n",
    "    stellar_mass = sat_mass[:,4]\n",
    "    \n",
    "    # convert central of masses into distance\n",
    "    distance = convert_dist(sat_cm, central_cm)\n",
    "    \n",
    "    # convert Mvir (virial mass) to Rvir (virial radius) using Colossus\n",
    "    cosmology.setCosmology('planck18')\n",
    "    central_rvir = np.array([mass_so.M_to_R(i, redshifts[list(central_mvir).index(i)], '200m') for i in central_mvir])\n",
    "    \n",
    "    # find snap of 2*rvir and sat mass at 2*rvir\n",
    "    ratio = distance / central_rvir\n",
    "\n",
    "    # find the first time the distance between the satellite and the central is less than 2 * central rvir\n",
    "    count = 0\n",
    "    prev = 0\n",
    "    snap = None\n",
    "    for i in ratio:\n",
    "        # distance check\n",
    "        if prev > 2 and i < 2 and snap is None:\n",
    "            snap = count\n",
    "\n",
    "        prev = i    \n",
    "        count += 1\n",
    "    \n",
    "    if snap is not None:\n",
    "        under_mass = sat_mass[snap, 4]\n",
    "        under_sfr = sat_sfr[snap]\n",
    "    \n",
    "        time_under = list(tng_data_099['info']['tree_t'])[snap]\n",
    "        \n",
    "    else:\n",
    "        print('No snap.')\n",
    "    \n",
    "    # error check\n",
    "    if [0,0,0] in sat_cm or [0,0,0] in central_cm:\n",
    "        print('[0,0,0] was found in either the sat\\'s or central\\'s center of mass. Likely an error.')\n",
    "\n",
    "    # change masses into an array and normalize it for coloring in future plot\n",
    "    # (pyplot colormap for viridis only takes values between 0 - 1)\n",
    "    \n",
    "    # also need to cut stellar_mass and sfr early to make norm arrays\n",
    "    \n",
    "    # also dividing by under mass for later graph\n",
    "    stellar_mass_log = np.log10(stellar_mass[end_index:start_index])\n",
    "    stellar_mass_div = stellar_mass[end_index:start_index] / under_mass\n",
    "    \n",
    "    mass_norm = find_norm_array(stellar_mass_log)\n",
    "    \n",
    "    # also dividing by under sfr for later graph\n",
    "    sat_sfr = sat_sfr[end_index:start_index]\n",
    "    sat_sfr_div = sat_sfr[end_index:start_index] / under_sfr\n",
    "    sat_sfr_norm = find_norm_array(sat_sfr)\n",
    "        \n",
    "    # only keeping the last 100-start_index snapshots\n",
    "    distance = distance[end_index:start_index]\n",
    "    \n",
    "    sat_sn = sat_sn[end_index:start_index]\n",
    "    sat_cm = sat_cm[end_index:start_index]\n",
    "    central_cm = central_cm[end_index:start_index]\n",
    "    central_rvir = central_rvir[end_index:start_index]\n",
    "    sat_mass = sat_mass[end_index:start_index]\n",
    "    sat_is_primary = sat_is_primary[end_index:start_index]\n",
    "    \n",
    "    times_o = times_o[end_index:start_index]\n",
    "        \n",
    "    # interpolate masses and distances (to make plots easier to look at)\n",
    "    distance_interp = interpolate(distance, times_o, start=start, end=end)\n",
    "    \n",
    "    mass_norm_interp = interpolate(mass_norm, times_o, start=start, end=end)\n",
    "    stellar_mass_interp = interpolate(stellar_mass_div, times_o, start=start, end=end)\n",
    "\n",
    "    central_rvir_interp = interpolate(central_rvir, times_o, start=start, end=end)\n",
    "    \n",
    "    sfr_norm_interp = interpolate(sat_sfr_norm, times_o, start=start, end=end)\n",
    "    sat_sfr_interp = interpolate(sat_sfr, times_o, start=start, end=end)\n",
    "    \n",
    "    # find maxes and mins of separation\n",
    "    maximums = signal.argrelextrema(distance_interp, np.greater)\n",
    "    minimums = signal.argrelextrema(distance_interp, np.less)\n",
    "    \n",
    "\n",
    "    # return data (distance_interp_cut, mass_norm_interp_cut, stellar_mass_interp_cut),\n",
    "    return (distance_interp, mass_norm_interp, stellar_mass_interp, sfr_norm_interp, sat_sfr_interp, central_rvir_interp), full_indices, snap, time_under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for the crowded plots:\n",
    "\n",
    "## We take in the data from find_data() and run it through here to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(start, start_index, end, end_index,\n",
    "             full_data, indices, mass_or_sfr,\n",
    "             bound_t, bound_ins_t, bound_exs_t, oshs_t, fuzz_t,\n",
    "             full_masses, closest):\n",
    "    \n",
    "    # random lists or values that you might ignore\n",
    "    colors_masses = ['red', 'orange', 'gold', 'green', 'blue', 'indigo', 'violet']\n",
    "    \n",
    "    r = np.linspace(start, end, 700)\n",
    "    \n",
    "    # let's setup the figure first in a pretty redundant way \n",
    "    # (setting all the axis manually because the plot i'm making is crowded)\n",
    "    fig = plt.figure(figsize=(90,70))\n",
    "\n",
    "    gs = fig.add_gridspec(7,8)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0:2, 0:5]) # distance vs time, colorbar mass, vert lines as snaps\n",
    "    ax2 = fig.add_subplot(gs[2:4, 0:5]) # mass and sep over time compared\n",
    "    ax3 = fig.add_subplot(gs[4:6, 0:5]) # sfr and sep over time compared \n",
    "    ax4 = fig.add_subplot(gs[6:7, 0:5]) # bound, fuzz total over time\n",
    "    \n",
    "    # below are all the bound, fuzz profiles on snapshots\n",
    "    ax5 = fig.add_subplot(gs[0, 5:8]), \n",
    "    ax6 = fig.add_subplot(gs[1, 5:8])\n",
    "    ax7 = fig.add_subplot(gs[2, 5:8]), \n",
    "    ax8 = fig.add_subplot(gs[3, 5:8]), \n",
    "    ax9 = fig.add_subplot(gs[4, 5:8]), \n",
    "    ax10 = fig.add_subplot(gs[5, 5:8]), \n",
    "    ax11 = fig.add_subplot(gs[6, 5:8]), \n",
    "    \n",
    "    # to titles and axes labels and all that jazz\n",
    "    \n",
    "    \n",
    "    #ax1\n",
    "    ax1.set_title('Separation Over Time', fontsize=100)\n",
    "    ax1.set_xlabel('Time / Gyr', fontsize=80)\n",
    "    ax1.set_ylabel(r'Separation / $R_{vir,central}$', fontsize=80)\n",
    "    \n",
    "    ax1.set_xlim(end - 0.2, start + 0.2)\n",
    "\n",
    "    #ax2\n",
    "    ax2b = ax2.twinx()\n",
    "    \n",
    "    ax2.set_title('Mass of Sat Against Sep', fontsize=100)\n",
    "    ax2.set_xlabel('Time / Gyr', fontsize=80)\n",
    "    ax2.set_ylabel(r'log$_{10}$(M$_{sat}$)', fontsize=80)\n",
    "    \n",
    "    ax2.spines['left'].set_color('blue')\n",
    "    ax2.tick_params(axis='y', colors='blue')\n",
    "    ax2.yaxis.label.set_color('blue')\n",
    "    \n",
    "    ax2.set_xlim(end - 0.2, start + 0.2)\n",
    "    \n",
    "    ax2b.set_ylabel('Separation / kpc', fontsize=80)\n",
    "\n",
    "    ax2b.spines['right'].set_color('red')\n",
    "    ax2b.tick_params(axis='y', colors='red')\n",
    "    ax2b.yaxis.label.set_color('red')\n",
    "    \n",
    "    #ax3\n",
    "    ax3b = ax3.twinx()\n",
    "    \n",
    "    ax3.set_title('Mass of Sat Against SFR', fontsize=100)\n",
    "    ax3.set_xlabel('Time / Gyr', fontsize=80)\n",
    "    ax3.set_ylabel(r'log$_{10}$(M$_{sat}$)', fontsize=80)\n",
    "    \n",
    "    ax3.spines['left'].set_color('blue')\n",
    "    ax3.tick_params(axis='y', colors='blue')\n",
    "    ax3.yaxis.label.set_color('blue')\n",
    "    \n",
    "    ax3.set_xlim(end - 0.2, start + 0.2)\n",
    "    \n",
    "    ax3b.set_ylabel('SFR (M* / yr)', fontsize=80)\n",
    "\n",
    "    ax3b.spines['right'].set_color('red')\n",
    "    ax3b.tick_params(axis='y', colors='red')\n",
    "    ax3b.yaxis.label.set_color('red')\n",
    "    \n",
    "    #ax4\n",
    "    ax4.set_title('Different Masses Over Time', fontsize=100)\n",
    "\n",
    "    ax4.set_xlabel('Time / Gyr', fontsize=80)\n",
    "    ax4.set_ylabel('log10(M*)', fontsize=80)\n",
    "    \n",
    "    #axs5-11\n",
    "    count = 0\n",
    "    for i in range(5,12):\n",
    "        axis = fig.axes[i-1]\n",
    "        \n",
    "        axis.set_title('snapshot: {}, redshift: {}'.format(snapshots[count], snap_z[count]), c=colors_masses[count], fontsize=80)\n",
    "\n",
    "        axis.set_xlabel('R / kpc', fontsize=60)\n",
    "        axis.set_ylabel(r'log$_{10}(M_{sun})$ / $\\mathrm{kpc}^{3}$', fontsize=60)\n",
    "        \n",
    "        count += 1 \n",
    "    \n",
    "    # now for the plotting itself\n",
    "    \n",
    "    # ax1\n",
    "    # average of the distance profiles\n",
    "    distance_profiles = full_data[:,0]\n",
    "    \n",
    "    if mass_or_sfr == 'mass':\n",
    "        colorbar_norm = full_data[:,1]\n",
    "        colorbar_notnorm = full_data[:,2]\n",
    "        \n",
    "        number = 1\n",
    "        \n",
    "    if mass_or_sfr == 'sfr':\n",
    "        colorbar_norm = full_data[:,3]\n",
    "        colorbar_notnorm = full_data[:,4]\n",
    "        \n",
    "        number = 3\n",
    "        \n",
    "    # remove problem indices\n",
    "    distance_redone, norm_redone, notnorm_redone = list(), list(), list()\n",
    "    for i in range(len(distance_profiles)):\n",
    "        d_prof, n_prof, nn_prof = distance_profiles[i], colorbar_norm[i], colorbar_notnorm[i]\n",
    "        \n",
    "        distance_redone.append(np.delete(d_prof, indices, axis=0))\n",
    "        norm_redone.append(np.delete(n_prof, indices, axis=0))\n",
    "        notnorm_redone.append(np.delete(nn_prof, indices, axis=0))\n",
    "    \n",
    "    av_profile = np.mean(np.array(distance_redone), axis=0)\n",
    "    av_norm_profile = np.mean(np.array(norm_redone), axis=0)\n",
    "    av_notnorm_profile = np.mean(np.array(notnorm_redone), axis=0)\n",
    "    \n",
    "    # each individual distance profile    \n",
    "    for i in full_data:\n",
    "        # i[0] is separation and i[5] is rvir of central\n",
    "        ax1.scatter(r, i[0] / i[5] , c=cm.viridis_r(i[number]))\n",
    "        \n",
    "        \n",
    "    # do colorbar info (depends on if mass or sfr)\n",
    "    colorbar = fig.colorbar(cm.ScalarMappable(norm=Normalize(min_c,\n",
    "                                     max_c), cmap='viridis_r'), ax=ax1)\n",
    "\n",
    "    # add colorbar name depending on mass_or_sfr)\n",
    "    if mass_or_sfr == 'mass':\n",
    "        colorbar.set_label(r'$M_{stellar, sat}$ / $M_{stellar, 2*rvir}$', fontsize=80)\n",
    "    \n",
    "    if mass_or_sfr == 'sfr':\n",
    "        colorbar.set_label(r'$SFR_{sat} (M_{sun, year}$ / $M_{sun, 2*rvir})$', fontsize=80)\n",
    "\n",
    "    # add vertical lines at snapshots and when under\n",
    "    for i in range(len(snap_times)):\n",
    "        if end - 0.2 < snap_times[i] < start + 0.2:\n",
    "            ax1.axvline(snap_times[i], c=colors_masses[i], label='z = ' + str(snap_z[i]), alpha=0.8)\n",
    "            \n",
    "    if time_under is not None:\n",
    "        ax1.axvline(time_under, c='black', label='under', alpha=0.8)\n",
    "    \n",
    "    # add horizontal line at sep / rvir = 2\n",
    "    ax1.axhline(y=2)\n",
    "    \n",
    "    # ax2\n",
    "    for i in full_data:\n",
    "        # i[0] is separation and i[5] is rvir of central\n",
    "        ax2.scatter(r, i[2], c='blue')\n",
    "        \n",
    "        # separation\n",
    "        ax2b.scatter(r, i[0], linestyle='dashed', c='red')\n",
    "        \n",
    "        \n",
    "    if time_under is not None:\n",
    "        ax2.axvline(time_under, c='black', label='under', alpha=0.8)\n",
    "    \n",
    "    \n",
    "    # ax3\n",
    "    for i in full_data:\n",
    "        # i[0] is separation and i[5] is rvir of central\n",
    "        ax3.scatter(r, i[2], c='blue')\n",
    "        \n",
    "        # separation\n",
    "        ax3b.scatter(r, i[4], linestyle='dashed', c='red')\n",
    "        \n",
    "        \n",
    "    if time_under is not None:\n",
    "        ax3.axvline(time_under, c='black', label='under', alpha=0.8)\n",
    "    \n",
    "    \n",
    "    # ax4\n",
    "    ax4.plot(snap_times, bound_t, c='red', label='bound')\n",
    "    ax4.plot(snap_times, bound_ins_t, c='green', label='insitu')\n",
    "    ax4.plot(snap_times, bound_exs_t, c='blue', label='exsitu')\n",
    "\n",
    "    ax4.axvline(time_under, c='black', label='under')\n",
    "    \n",
    "    \n",
    "    # axs5-11\n",
    "    count = 0\n",
    "    for i in range(5, 12):\n",
    "        axis = fig.axes[i-1]\n",
    "        \n",
    "        mass_types = full_masses[count]\n",
    "        snapnum = snapshots[count]\n",
    "\n",
    "        bins is mass_types[5]\n",
    "        #axis.plot(mass_types[6], np.log10(mass_types[0]), c='red', label='bound')\n",
    "        axis.plot(mass_types[6], np.log10(mass_types[0]), c='red')\n",
    "        #axis.plot(mass_types[6], np.log10(mass_types[1]), c='green', label='insitu')\n",
    "        axis.plot(mass_types[6], np.log10(mass_types[1]), c='green')\n",
    "        #axis.plot(mass_types[6], np.log10(mass_types[2]), c='blue', label='exsitu')\n",
    "        axis.plot(mass_types[6], np.log10(mass_types[2]), c='blue')\n",
    "        #axis.plot(mass_types[6], np.log10(mass_types[4]), c='orange', label='fuzz')\n",
    "        axis.plot(mass_types[6], np.log10(mass_types[4]), c='orange')\n",
    "\n",
    "        #if snapshot == closest, add to other snapshots\n",
    "        if snapnum == closest:\n",
    "            for j in range(5, 12):\n",
    "                axis_b = fig.axes[j-1]\n",
    "                \n",
    "                axis_b.plot(mass_types[6], np.log10(mass_types[0]), c='red', alpha=0.5, label='bound, ' + str(closest), linestyle='dashed')\n",
    "                axis_b.plot(mass_types[6], np.log10(mass_types[1]), c='green', alpha=0.5, label='insitu, ' + str(closest), linestyle='dashed')\n",
    "                axis_b.plot(mass_types[6], np.log10(mass_types[2]), c='blue', alpha=0.5, label='exsitu, ' + str(closest), linestyle='dashed')\n",
    "                axis_b.plot(mass_types[6], np.log10(mass_types[4]), c='orange', alpha=0.5, label='fuzz, ' + str(closest), linestyle='dashed')\n",
    "                #axis_b.plot(mass_types[6], np.log10(mass_types[0]), c='red', alpha=0.5, linestyle='dashed')\n",
    "                #axis_b.plot(mass_types[6], np.log10(mass_types[1]), c='green', alpha=0.5, linestyle='dashed')\n",
    "                #axis_b.plot(mass_types[6], np.log10(mass_types[2]), c='blue', alpha=0.5, linestyle='dashed')\n",
    "                #axis_b.plot(mass_types[6], np.log10(mass_types[4]), c='orange', alpha=0.5, linestyle='dashed')\n",
    "    \n",
    "        count += 1\n",
    "    \n",
    "    # adding legends at the end\n",
    "    for i in fig.axes:\n",
    "            i.legend(loc='upper right', prop={'size': 40})\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # close plots to save memory\n",
    "    plt.close()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that I've defined all the functions, let's work on getting satellites to run the code.\n",
    "\n",
    "## First, do a mass cut of all my satellites (log10(Mstellar,sat) > 11.4 at *any* z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# code to look at satellites and see if \n",
    "# the plan is to run through each satellite, if at some point the mass is greater than \n",
    "# our cutoff, then mark it down to add\n",
    "all_l, all_central_l = list(), list()\n",
    "for i in range(len(tree_SubhaloMassType)):\n",
    "    if is_primary_099[i] == 1:\n",
    "        central_i = i\n",
    "        \n",
    "    else:\n",
    "        stellar_masses = np.log10(tree_SubhaloMassType[i,:,4])\n",
    "\n",
    "        check = any(i >= 11.4 for i in stellar_masses)\n",
    "        \n",
    "        if check == True:\n",
    "            all_l.append(i)\n",
    "            all_central_l.append(central_i)\n",
    "\n",
    "    \n",
    "sat_index = all_l\n",
    "central_index = all_central_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second, the data may have errors where a given satellite does not have a central to go along with it. Check that they do through each file, cut the ones that don't: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now to check if my centrals exist\n",
    "# iterate through each file, where iterate through each galaxy. check if the group id of that galaxy has a host\n",
    "really_catch_dict = dict()\n",
    "for i in file_list:\n",
    "    print('Dealing with file: {}'.format(i))\n",
    "\n",
    "    tng_data_z = h5py.File(file_path + i, 'r')\n",
    "\n",
    "    # find snapshot num \n",
    "    snapnum = int(i[29:31])\n",
    "\n",
    "    match, goodmatch, idx = find_id(tng_data_099, tng_data_z, snapnum)\n",
    "\n",
    "    # find if high or low redshift\n",
    "    if i == file_list[0]:\n",
    "        high_z = False\n",
    "        matcher = goodmatch\n",
    "\n",
    "    else:\n",
    "        high_z = True\n",
    "        matcher = match\n",
    "\n",
    "    tng_catgrp_id = find_catgrp_id(tng_data_z, matcher, idx, high_z)\n",
    "\n",
    "    # run through each index in sat_index to find the specific catgrp_ids need to look out for\n",
    "    grp_id_lookout_list = list()\n",
    "    for j in sat_index:\n",
    "        if high_z == False:\n",
    "            grp_id_lookout_list.append(tng_catgrp_id[match][j])\n",
    "\n",
    "        if high_z == True:\n",
    "            grp_id_lookout_list.append(tng_catgrp_id[match[j]])\n",
    "\n",
    "    grp_ids = list(tng_data_z['catgrp_id'])\n",
    "    primaries = list(tng_data_z['catgrp_is_primary'])\n",
    "    gal_dict = dict()\n",
    "    for j in range(len(list(grp_ids))):\n",
    "        current_grp_id = grp_ids[j]\n",
    "        primary = primaries[j]\n",
    "\n",
    "        # add group id\n",
    "        if current_grp_id not in list(gal_dict.keys()):\n",
    "            gal_dict[current_grp_id] = 0\n",
    "\n",
    "        # change value to 1 if is central\n",
    "        if primary == 1:\n",
    "            gal_dict[current_grp_id] = 1\n",
    "\n",
    "    # check if any 0s\n",
    "    keys = list(gal_dict.keys())\n",
    "    catch, really_catch = list(), list()\n",
    "    for j in keys:\n",
    "        if gal_dict[j] == 0:\n",
    "            if j in grp_id_lookout_list:\n",
    "                really_catch.append(j)\n",
    "            else:\n",
    "                catch.append(j)\n",
    "\n",
    "    really_catch_dict[i] = really_catch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third, I also only want galaxies that are satellites for a longer period of time (should see more evidence of tidal stripping):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to find galaxies that are satellites for quite a while\n",
    "consistent_sat, consistent_central = list(), list()\n",
    "for i in range(len(sat_index)):\n",
    "    # get trees\n",
    "    sat_is_primary = tree_is_primary[sat_index[i], :]\n",
    "    \n",
    "    tree_tophat_s = tree_Group_M_TopHat200[sat_index[i]]\n",
    "    tree_tophat_c = tree_Group_M_TopHat200[central_index[i]]\n",
    "    \n",
    "    # cut is_primary tree to wanted length (keeping the last 20)\n",
    "    sat_is_primary = sat_is_primary[len(sat_is_primary) - 20:]\n",
    "    \n",
    "    # see if conforms to what want\n",
    "    count = list(sat_is_primary).count(True)\n",
    "    same = list(tree_tophat_s[80:] == tree_tophat_c[80:]).count(True) == 20  \n",
    "    \n",
    "    if count == 0 and same is True:\n",
    "        consistent_sat.append(sat_index[i])\n",
    "        consistent_central.append(central_index[i])\n",
    "\n",
    "# remove certain points from the list\n",
    "# centrals at 0,0 at points\n",
    "# note that i did this manually\n",
    "zero_index = [list(consistent_sat).index(250), list(consistent_sat).index(282), \n",
    "              list(consistent_sat).index(366), list(consistent_sat).index(424), \n",
    "              list(consistent_sat).index(429), list(consistent_sat).index(433), \n",
    "              list(consistent_sat).index(459), list(consistent_sat).index(499), \n",
    "              list(consistent_sat).index(584), list(consistent_sat).index(609),\n",
    "              list(consistent_sat).index(983)]\n",
    "\n",
    "remove_index = zero_index #+ inf_index\n",
    "\n",
    "consistent_sat_r = np.delete(np.array(consistent_sat), remove_index)\n",
    "consistent_central_r = np.delete(np.array(consistent_central), remove_index)\n",
    "\n",
    "#choose a number of random indexes to use\n",
    "number = 2\n",
    "\n",
    "rand_indices = random.choices(list(range(len(consistent_sat_r))), k=number)\n",
    "\n",
    "consistent_sat_r = consistent_sat_r[rand_indices]\n",
    "consistent_central_r = consistent_central_r[rand_indices]\n",
    "\n",
    "print('sat:', list(consistent_sat_r))\n",
    "print('cent:', list(consistent_central_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the needed satellite cuts out of the way, let's run the code from the functions above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# code to look at individual plots of the satellite's position relative to the centrals.\n",
    "# is tracked across all snapshots via tree, and colorcoded by the mass of the satellite\n",
    "\n",
    "# 'mass' or 'sfr'\n",
    "mass_or_sfr = 'mass'\n",
    "\n",
    "# start at z=0\n",
    "start_index = 99\n",
    "start_time = times[start_index]\n",
    "\n",
    "# which redshift indix to end at (indices closer to 99 start later than indices closer to 0.)\n",
    "# index of 0 is the earliest snapshot we have\n",
    "end_index = 50\n",
    "end_time = times[end_index]\n",
    "\n",
    "\n",
    "# run through each satellite and make the plot individually\n",
    "for i in range(len(consistent_sat_r)):\n",
    "    # show what satellite am working on   \n",
    "    print('Working on index: {} / sat: {}'.format(i, consistent_sat_r))\n",
    "    \n",
    "    # initialize data\n",
    "    full_data = list()\n",
    "    full_indices = list()\n",
    "    full_switch = list()\n",
    "    \n",
    "    max_c, min_c = np.nan, np.nan\n",
    "    \n",
    "    #grab which sat and central pair are looking at right now\n",
    "    sat = consistent_sat_r[i]\n",
    "    central = consistent_central_r[i]\n",
    "\n",
    "    # find the data like before\n",
    "    data, indices, snap_under, time_under = find_data(sat, central, \n",
    "                                              start_index=start_index, start=start_time, \n",
    "                                              end_index = end_index, end=end_time)\n",
    "    \n",
    "    # parse certain data\n",
    "    distance = data[0]\n",
    "    mass_norm = data[1]\n",
    "    stellar_mass = data[2]\n",
    "    sfr_norm = data[3]\n",
    "    sat_sfr = data[4]\n",
    "    central_rvir = data[5]\n",
    "    \n",
    "    # if a galaxy without the 0,0,0 error\n",
    "    if data is not None: \n",
    "        full_data.append(data)\n",
    "        full_indices.extend(list(indices))\n",
    "\n",
    "        # add to max and min as needed for colorbar (hence *_c)  \n",
    "        if np.isnan(max_c) and np.isnan(min_c):\n",
    "            max_c = np.nanmax(stellar_mass)\n",
    "            min_c = np.nanmin(stellar_mass)\n",
    "\n",
    "        if max_c < np.nanmax(stellar_mass):\n",
    "            max_c = np.nanmax(stellar_mass)\n",
    "\n",
    "        if min_c > np.nanmin(stellar_mass):\n",
    "            min_c = np.nanmin(stellar_mass)\n",
    "\n",
    "    # remove duplicates from indices\n",
    "    indices_new = [] \n",
    "    [indices_new.append(x) for x in full_indices if x not in indices_new] \n",
    "\n",
    "    # keep indices after the start_index\n",
    "    indices_new = [i for i in indices_new if i <= start_index]\n",
    "\n",
    "    # find where to put vertical lines (at snapshots)\n",
    "    snapshots = [99, 84, 72, 67, 59, 50, 40]\n",
    "    snap_times = times[snapshots]\n",
    "    snap_z = redshifts[snapshots]\n",
    "    \n",
    "    # find which snapshot was closest to switch\n",
    "    closest = min(snapshots, key=lambda x:abs(x-snap_under))\n",
    "    \n",
    "    # plot fig\n",
    "\n",
    "    bound_t, bound_ins_t, bound_exs_t, oshs_t, fuzz_t = list(), list(), list(), list(), list()\n",
    "    full_masses, full_distances = list(), list()\n",
    "    for i in reversed(range(len(file_list))):\n",
    "        # first, let's get the data ready for plotting\n",
    "        \n",
    "        # snapnum\n",
    "        snapnum = int(file_list[i][29:31])\n",
    "\n",
    "        redshift_z = redshifts[snapnum]\n",
    "\n",
    "        # h5py file itself\n",
    "        tng_data_z = h5py.File(file_path + file_list[i], 'r')\n",
    "\n",
    "        # used to match galaxies across files\n",
    "        match, goodmatch, idx = find_id(tng_data_099, tng_data_z, snapnum)\n",
    "\n",
    "        # find matcher and high_z by where in file_list/if z=0 or not\n",
    "        if i == 0:\n",
    "            matcher = goodmatch\n",
    "            high_z = False\n",
    "\n",
    "        else:\n",
    "            matcher = match\n",
    "            high_z = True\n",
    "\n",
    "        # find sfr\n",
    "        sfr = find_star_formation(tng_data_z, matcher, idx, sat, high_z)\n",
    "\n",
    "        # grab masses of galaxy\n",
    "        bound, bound_insitu, bound_exsitu, oshs, fuzz, volume, bins = find_3d_masses(tng_data_z, matcher, idx, sat, high_z)\n",
    "        full_masses.append((bound, bound_insitu, bound_exsitu, oshs, fuzz, volume, bins))\n",
    "\n",
    "        distance = find_distances(tng_data_z, matcher, idx, sat, central, redshift_z, high_z)\n",
    "        full_distances.append(distance)\n",
    "        \n",
    "        # for ax4\n",
    "        bound_t.append(np.log10(sum(bound * volume)))\n",
    "        bound_ins_t.append(np.log10(sum(bound_insitu * volume)))\n",
    "        bound_exs_t.append(np.log10(sum(bound_exsitu * volume)))\n",
    "        oshs_t.append(np.log10(sum(oshs * volume)))\n",
    "        fuzz_t.append(np.log10(sum(fuzz * volume)))\n",
    "        \n",
    "    # run the now processed data through the plotting function\n",
    "    fig = plot_all(start_time, start_index, end_time, end_index,\n",
    "             np.array(full_data), np.array(indices_new), 'mass',\n",
    "             bound_t, bound_ins_t, bound_exs_t, oshs_t, fuzz_t,\n",
    "             full_masses, closest)\n",
    "    \n",
    "    # save to whichever folder and with whichever filename you want\n",
    "    fig.savefig('sat_{}.png'.format(sat), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's also helpful to look at the 2D profiles of galaxies (had been doing 3D). The classes and functions used were written by Song (like GalaxyMap, aper_summary(), etc.)\n",
    "\n",
    "## This is how you look at the 2D profile for a specific galaxy using his code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to look at the profiles of the galaxies using crusher (another check)\n",
    "tng_data = BeneMassAgeZMaps(file_path + file_list[0], label='tng100')\n",
    "\n",
    "total = list()\n",
    "for i in range(len(consistent_sat_r)):\n",
    "    print('Dealing with galaxy {} out of {}...'.format(i+1, len(consistent_sat_r)))\n",
    "    \n",
    "    gal = GalaxyMap(tng_data, consistent_sat_r[i], proj='xy')\n",
    "\n",
    "    gal.aper_summary()\n",
    "    gal.ell_summary()\n",
    "    \n",
    "    prof = visual.prepare_show_ellipse(gal.info, gal.maps, gal.ell_sum)\n",
    "    \n",
    "    mass_profile = prof['ell_gal_3']['intens']\n",
    "    radius = prof['ell_gal_3']['r_kpc']\n",
    "    \n",
    "    total.append((mass_profile, radius))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a check, I was comparing the subhalo velocity, star formation rates, and velocity distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "field_l = ['tree_SubhaloVel', 'tree_SubhaloSFR', 'tree_SubhaloVelDisp']\n",
    "number = 0\n",
    "gal = 33\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(np.abs(tng_data_099[field_l[number]][gal,:,0]) + np.abs(tng_data_099[field_l[number]][gal,:,1]) + np.abs(tng_data_099[field_l[number]][gal,:,2]))\n",
    "ax2.scatter(np.linspace(0,99, len(tng_data_099['tree_is_primary'][gal])), tng_data_099['tree_is_primary'][gal], s=1, c='r', alpha=0.6)\n",
    "\n",
    "ax1.set_ylabel(field_l[number], c='b')\n",
    "ax2.set_ylabel('is_primary', c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is just a previous list of satellites and centrals I was using. I don't think you need to pay this much heed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "previous sats/centrals (20 without central check):\n",
    "\n",
    "sat: [3, 4, 5, 7, 10, 11, 16, 17, 19, 20, 21, 23, 25, 29, 43, 46, 49, 54, 57, 59, 60, 69, 90, 92, 107, 111, 117, 118, 124, 126, 136, 138, 140, 145, 146, 147, 150, 151, 156, 157, 161, 163, 164, 169, 171, 172, 174, 176, 179, 185, 187, 189, 191, 192, 194, 197, 201, 203, 208, 211, 214, 215, 237, 245, 246, 252, 254, 269, 270, 279, 288, 289, 293, 294, 295, 299, 302, 306, 327, 342, 354, 359, 361, 364, 371, 374, 376, 377, 393, 408, 409, 427, 440, 442, 444, 447, 449, 465, 472, 504, 508, 516, 536, 546, 558, 587, 605, 626, 627, 632, 635, 642, 677, 682, 683, 699, 703, 724, 748, 759, 792, 805, 816, 848, 862, 894, 900, 922, 970, 1073, 1209, 1211, 1281, 1283, 1371, 1421, 1455, 1673]\n",
    "cent: [0, 0, 0, 0, 0, 0, 12, 12, 12, 12, 12, 22, 22, 22, 41, 41, 47, 51, 51, 51, 51, 62, 89, 89, 104, 108, 115, 115, 123, 123, 132, 132, 139, 142, 142, 142, 148, 148, 154, 154, 160, 160, 160, 165, 170, 170, 170, 175, 175, 184, 184, 184, 190, 190, 193, 195, 198, 198, 207, 210, 213, 213, 232, 244, 244, 251, 251, 267, 267, 277, 287, 287, 291, 291, 291, 298, 301, 304, 326, 341, 353, 358, 360, 363, 370, 372, 375, 375, 392, 406, 406, 426, 437, 441, 443, 446, 448, 464, 471, 503, 506, 515, 535, 544, 557, 586, 603, 625, 625, 631, 633, 640, 676, 681, 681, 698, 702, 723, 747, 758, 791, 804, 814, 846, 861, 893, 899, 921, 969, 1072, 1208, 1210, 1280, 1282, 1370, 1420, 1454, 1672]\n",
    "\"\"\";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
